{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linkit Beginner Challenge: Explainable Machine Learning using SHAP\n",
    "\n",
    "SHAP (**SH**apley **A**dditive ex**P**lanations) can be used to interpret any model, i.e. it is **model-agnostic**\n",
    "It is not necessary to fully understand the math behind SHAP, because this can get quite complex. For us, it is enough to understand how we can use them to explain machine learning models.\n",
    "\n",
    "You can read more on SHAP in the [original paper](https://arxiv.org/abs/1705.07874) or on several tutorials like this [beginner intro](https://www.kaggle.com/code/dansbecker/shap-values) to shap values and the [advanced use cases tutorial](https://www.kaggle.com/code/dansbecker/advanced-uses-of-shap-values/tutorial)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task\n",
    "\n",
    "Your task is to (1) train a classifier and (2) explain the classifier's predictions with shap values\n",
    "\n",
    "Your submission we will be evaluated on the Accuracy of the classifer, as well as how well the explanation fit to the actual value.\n",
    "For this, a few selected test points are held aside, for which you do not know the true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    LabelEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"data\", \"bank.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"deposit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes Description: <br>\n",
    "\n",
    "###  Bank client data:<br>\n",
    "<a id=\"bank_client_data\"></a>\n",
    "1 - **age:** (numeric)<br>\n",
    "2 - **job:** type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')<br>\n",
    "3 - **marital:** marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)<br>\n",
    "4 - **education:** (categorical: primary, secondary, tertiary and unknown)<br>\n",
    "5 - **default:** has credit in default? (categorical: 'no','yes','unknown')<br>\n",
    "6 - **housing:** has housing loan? (categorical: 'no','yes','unknown')<br>\n",
    "7 - **loan:** has personal loan? (categorical: 'no','yes','unknown')<br>\n",
    "8 - **balance:** Balance of the individual.\n",
    "### Related with the last contact of the current campaign:\n",
    "<a id=\"last_contact\"></a>\n",
    "8 - **contact:** contact communication type (categorical: 'cellular','telephone') <br>\n",
    "9 - **month:** last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')<br>\n",
    "10 - **day:** last contact day of the week (categorical: 'mon','tue','wed','thu','fri')<br>\n",
    "11 - **duration:** last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.<br>\n",
    "### other attributes:<br>\n",
    "<a id=\"other_attributes\"></a>\n",
    "12 - **campaign:** number of contacts performed during this campaign and for this client (numeric, includes last contact)<br>\n",
    "13 - **pdays:** number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)<br>\n",
    "14 - **previous:** number of contacts performed before this campaign and for this client (numeric)<br>\n",
    "15 - **poutcome:** outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')<br>\n",
    "\n",
    "Output variable (desired target):<br>\n",
    "21 - **deposit** - has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#FA5858\", \"#64FE2E\"]\n",
    "labels = \"Did not Open Term Suscriptions\", \"Opened Term Suscriptions\"\n",
    "df[TARGET].value_counts().plot.pie(\n",
    "    explode=[0, 0.25],\n",
    "    autopct=\"%1.2f%%\",\n",
    "    shadow=True,\n",
    "    startangle=25,\n",
    "    colors=colors,\n",
    "    labels=labels,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Term Deposit? \n",
    "A **Term deposit** is a deposit that a bank or a financial institurion offers with a fixed rate (often better than just opening deposit account) in which your money will be returned back at a specific maturity time. For more information with regards to Term Deposits please click on this link from Investopedia:  https://www.investopedia.com/terms/t/termdeposit.asp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We have categorical features, so we need to apply some encoding and also label encoding on the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display = df.copy()\n",
    "X_display = df.drop(columns=TARGET, axis=1)\n",
    "\n",
    "df[\"deposit\"] = LabelEncoder().fit_transform(df[\"deposit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical = df.select_dtypes(include=\"object\")\n",
    "\n",
    "for col in df_categorical.keys():\n",
    "    df[col] = OrdinalEncoder(encoded_missing_value=-1, dtype=np.int64).fit_transform(\n",
    "        df[col].values.reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "First, we need to split the data into a training and test set. We do this with the `train_test_split` function provided by `sklearn`.\n",
    "\n",
    "Then, a simple `DecisionTreeClassifier` is fitted on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=TARGET, axis=1)\n",
    "y = df[TARGET]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, shuffle=True, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this classifier overfits a lot, because the score on the test set is much lower. This is common with Decision trees with default parameters.\n",
    "\n",
    "Feel free to change the classifier and its parameters or use hyper-parameter optimization frameworks like [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) or [Optuna](https://optuna.org/) or just the exhaustive Grid Search of `sklearn` (`sklearn.model_selection.GridSearchCV`) to improve on the classifier performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X)[1]\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot is called a beeswarm plot and shows the shap values for *each sample* represented by a dot in the beeswarm plot.\n",
    "\n",
    "Each dot has three characteristics:\n",
    "\n",
    "- Vertical location shows what feature it is depicting\n",
    "- Color shows whether that feature was high or low for that row of the dataset\n",
    "- Horizontal location shows whether the effect of that value caused a higher or lower prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[1],\n",
    "    shap_values[idx, :],\n",
    "    X_display.iloc[idx, :],\n",
    "    link=\"logit\",\n",
    ")  # link=logit transforms the log-odds (raw output of the model) into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value[1], shap_values[:1000, :], X_display.iloc[:1000, :]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence Contribution Plots\n",
    "\n",
    "SHAP dependence plots show the effect of a single feature across the whole dataset. They plot a feature’s value vs. the SHAP value of that feature across many samples. SHAP dependence plots are similar to partial dependence plots, but account for the interaction effects present in the features, and are only defined in regions of the input space supported by data. The vertical dispersion of SHAP values at a single feature value is driven by interaction effects, and another feature is chosen for coloring to highlight possible interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X.columns:\n",
    "    shap.dependence_plot(name, shap_values, X, display_features=X_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkit-beginner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0c909ad250953ec8abba4bf40b04cb9a37dac6afed3437f90d6edc7154e1a0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
